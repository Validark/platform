on:
  workflow_call:
    inputs:
      command:
        description: Run tests command
        type: string
        default: test
        required: true

jobs:
  test-suite:
    name: Run Test Suite
    # TODO: Try with Github Runner, probably it will be the same time
    runs-on: [ "self-hosted", "linux", "x64", "ubuntu-platform" ]
    timeout-minutes: 120
    steps:
      - name: Check out repo
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Login to DockerHub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}

      - name: Configure AWS credentials and bucket region
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-region: ${{ vars.AWS_REGION }}

      - name: Setup Node.JS
        uses: ./.github/actions/nodejs

      - name: Restore JS build artifacts
        uses: everpcpc/actions-cache@v1
        with:
          bucket: multi-runner-linux-x64-platform-cache-ui535z23
          root: actions-cache
          path: build-js-artifacts-${{ github.sha }}.tar
          key: build-js-artifacts/${{ github.sha }}

      - name: Unpack JS build artifacts archive
        run: tar -xf build-js-artifacts-${{ github.sha }}.tar

      - name: Pull dashmate image
        shell: bash
        run: |
          # Login to ECR
          DOCKER_HUB_ORG="${{ vars.AWS_ACCOUNT_ID }}.dkr.ecr.${{ vars.AWS_REGION }}.amazonaws.com"
          aws ecr get-login-password --region ${{ vars.AWS_REGION }} | docker login --username AWS --password-stdin $DOCKER_HUB_ORG

          SHA_TAG=sha-${{ github.sha }}
          VERSION=$(cat package.json | jq -r '.version')

          docker pull $DOCKER_HUB_ORG/dashmate_helper:$SHA_TAG
          docker tag $DOCKER_HUB_ORG/dashmate_helper:$SHA_TAG dashpay/dashmate_helper:$VERSION

      - name: Get dashmate fingerprint
        id: dashmate-fingerprint
        run: echo "sha=$(git log -1 --format="%h" -- packages/dashmate)" >> $GITHUB_OUTPUT

      - name: Restore local network data
        id: local-network-data
        uses: strophy/actions-cache/restore@opendal-update
        with:
          bucket: multi-runner-linux-x64-platform-cache-ui535z23
          root: local-network-data
          path: |
            /home/ubuntu/.dashmate
            **/.env
            dashmate_volumes_dump
          key: local-network-volumes/${{ steps.dashmate-fingerprint.outputs.sha }}

      - name: Restore dashmate volumes
        run: |
          # Directory where volume dumps are stored
          volume_dump_dir="dashmate_volumes_dump"
          dump_file="$volume_dump_dir/data.tar.gz"
          metadata_file="$volume_dump_dir/metadata.json"

          # Read each line (metadata for each volume) and recreate the volume
          cat $metadata_file | jq -c '.[]' | while read -r metadata; do
            volume=$(echo $metadata | jq -r '.Name')
            labels=$(echo $metadata | jq -r '.Labels | to_entries | map("--label \(.key)=\(.value)") | .[]')

            # Create volume with labels
            docker volume create $labels $volume
          done

          # Restore all volumes from the tarball
          docker run --rm \
            $(cat $metadata_file | jq -r '.[].Name' | xargs -I {} echo -n "-v {}:/dashmate_volumes/{} ") \
            -v $(pwd)/$volume_dump_dir:/backup busybox tar xf /backup/data.tar.gz -C /dashmate_volumes
        shell: bash
        if: steps.local-network-data.outputs.cache-hit == 'true'

      - name: Setup local network
        run: |
          set -ex

          # create tenderdash blocks every 10s to speed up test suite
          yarn dashmate config set --config=local platform.drive.tenderdash.consensus.createEmptyBlocksInterval "10s"

          # collect drive logs for bench suite
          yarn dashmate config set --config=local platform.drive.abci.logs.stdout.level "trace"

          SHA_TAG=sha-${{ github.sha }}
          DOCKER_HUB_ORG="${{ vars.AWS_ACCOUNT_ID }}.dkr.ecr.${{ vars.AWS_REGION }}.amazonaws.com"

          # Drive
          yarn dashmate config set --config=local platform.drive.abci.docker.image $DOCKER_HUB_ORG/drive:$SHA_TAG

          # DAPI
          yarn dashmate config set --config=local platform.dapi.api.docker.image $DOCKER_HUB_ORG/dapi:$SHA_TAG

          ./scripts/setup_local_network.sh
          ./scripts/configure_test_suite.sh
          ./scripts/configure_dotenv.sh
        shell: bash
        if: steps.local-network-data.outputs.cache-hit != 'true'

      - name: Dump dashmate volumes
        run: |
          # Directory where volume dumps will be stored
          volume_dump_dir="dashmate_volumes_dump"
          dump_file="$volume_dump_dir/data.tar.gz"
          metadata_file="$volume_dump_dir/metadata.json"

          mkdir -p $volume_dump_dir

          # Initialize the volume mount arguments
          volume_mounts=""

          # Initialize metadata file
          echo "[]" > $metadata_file

          # Temporary file for individual volume metadata
          temp_metadata_file="$volume_dump_dir/temp_metadata.json"

          # Loop through each volume, prepare mounts and save metadata
          for volume in $(docker volume ls --filter name=dashmate_ -q); do
            volume_mounts="$volume_mounts -v $volume:/all_volumes/$volume"
            
            # Get metadata for the current volume
            docker volume inspect $volume > $temp_metadata_file

            # Append metadata to the main file
            # Merge the current metadata array with the existing one
            jq -s '.[0] + .[1]' $metadata_file $temp_metadata_file > $temp_metadata_file && mv $temp_metadata_file $metadata_file
          done

          # Cleanup temporary metadata file
          rm $temp_metadata_file

          # Run a container with all volumes mounted and perform the dump
          docker run --rm $volume_mounts -v $(pwd)/volume_dumps:/backup ubuntu tar czf /backup/all_volumes.tar.gz -C /all_volumes .
        shell: bash
        if: steps.local-network-data.outputs.cache-hit != 'true'

      - name: Save local network data
        uses: strophy/actions-cache/save@opendal-update
        with:
          bucket: multi-runner-linux-x64-platform-cache-ui535z23
          root: local-network-data
          path: |
            /home/ubuntu/.dashmate
            **/.env
            dashmate_volumes_dump
          key: local-network-volumes/${{ steps.dashmate-fingerprint.outputs.sha }}
        if: steps.local-network-data.outputs.cache-hit != 'true'

      - name: Start local network
        run: yarn start

      - name: Run Wallet functional tests
        run: yarn workspace @dashevo/wallet-lib test:functional

      - name: Run SDK functional tests
        run: yarn workspace dash test:functional

      - name: Run test suite
        run: yarn workspace @dashevo/platform-test-suite ${{ inputs.command }}

      - name: Show Docker logs
        if: ${{ failure() }}
        uses: jwalton/gh-docker-logs@v2
